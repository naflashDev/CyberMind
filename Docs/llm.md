# ü§ñ LLM Integrado: Alcance y Uso

Este documento describe el prop√≥sito, l√≠mites y recomendaciones de uso del **LLM** integrado en CyberMind.

---

## üéØ Prop√≥sito

El LLM act√∫a como asistente t√©cnico especializado para:

- Explicar y contextualizar **CVE** (Common Vulnerabilities and Exposures)
- Resumir noticias y textos extra√≠dos por los scrapers
- Ayudar con an√°lisis t√©cnicos relacionados con inform√°tica y ciberseguridad

> ‚ö†Ô∏è **Nota:** El LLM no sustituye fuentes oficiales ni realiza atribuciones definitivas. Complementa el an√°lisis, pero siempre verifica en fuentes oficiales para decisiones cr√≠ticas.

---

## üì¶ Alcance y limitaciones

| Aspecto | Detalle |
|:---|:---|
| **Dominio** | CVE, vulnerabilidades, mitigaciones, indicadores t√©cnicos, res√∫menes de noticias |
| **Datos de entrenamiento** | Solo documentos y noticias scrapeados y procesados por el sistema (outputs/result.json, √≠ndices en OpenSearch) |
| **Limitaciones** | No da consejos fuera del √°mbito t√©cnico ni debe usarse para decisiones legales sin verificaci√≥n humana |

---

## ü¶ô Modelo utilizado y restricciones

El sistema de IA de CyberMind utiliza un modelo **LLama3** restringido, configurado mediante un archivo **Model file** que limita sus respuestas y comportamiento. La base de conocimiento del modelo est√° limitada hasta el a√±o **2023** y no incluye informaci√≥n posterior.

> ‚ö†Ô∏è **Importante:** El modelo actual **NO ha sido finetuneado** con los datos extra√≠dos por el sistema. La funci√≥n de entrenamiento personalizado (finetuning) se implementar√° en el futuro, ya que el proceso es altamente demandante en recursos y tiempo.

- El modelo responde √∫nicamente sobre temas de ciberseguridad y CVE seg√∫n las restricciones del Model file.
- No puede responder sobre eventos, vulnerabilidades o noticias posteriores a 2023.
- El finetuning con datos propios est√° planificado como mejora futura.
- El archivo JSON para el finetuning **s√≠ se genera** autom√°ticamente (`outputs/finetune_data.jsonl`), pero no se utiliza a√∫n para entrenar el modelo.

---

## üîó Endpoints relevantes

| M√©todo | Ruta | Descripci√≥n |
|:---:|:---|:---|
| POST | `/llm/query` | Enviar prompt y recibir respuesta |
| GET | `/llm/updater` | Inicia el proceso peri√≥dico de actualizaci√≥n/finetune del LLM |
| GET | `/llm/stop-updater` | Detiene el proceso iniciado |

---

## üìù Buenas pr√°cticas al formular prompts

- S√© espec√≠fico: incluye identificadores como `CVE-YYYY-NNNN` cuando los tengas
- Pide res√∫menes breves si necesitas rapidez: `Resume CVE-2024-4320 en 3 puntos`
- Evita prompts ambiguos o fuera de dominio (por ejemplo, pol√≠tica general no relacionada con vulnerabilidades)

---

## üñ•Ô∏è Recomendaciones de infraestructura

- Uso intensivo: se recomienda GPU (NVIDIA/CUDA) para evitar sobrecargas de CPU/memoria
- Sin GPU: controla la concurrencia y desactiva tareas autom√°ticas de finetuning en producci√≥n

---

## üß© Integraci√≥n con la UI

- El chat **CyberSentinel** est√° integrado en la UI principal (`/ui`)
- Desde la UI puedes iniciar el `llm_updater` y ver el historial de interacciones

---

## ‚ö° Inicio autom√°tico de servicios

Al arrancar `main.py`, la aplicaci√≥n puede iniciar servicios adicionales (contenedores Docker para OpenSearch/TinyRSS, procesos locales para el LLM) si est√° habilitado en la configuraci√≥n (`cfg.ini`, carpeta `Install/`).

---

## üîí Privacidad y datos

- El LLM procesa internamente los textos scrapeados; no env√≠a datos a servicios externos por defecto
- Si conectas un proveedor externo (Ollama, OpenAI, etc.), actualiza la documentaci√≥n y la pol√≠tica de privacidad

---

## üõ†Ô∏è Notas operativas

- El `llm_updater` puede ejecutar tareas de actualizaci√≥n peri√≥dica (clon de repositorios CVE, construcci√≥n de dataset, fine-tuning). Controla su ejecuci√≥n desde la UI
- En entornos de pruebas/CI desactiva el updater autom√°tico para evitar llamadas largas o dependencias externas